{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13f71cb7",
      "metadata": {
        "id": "13f71cb7"
      },
      "outputs": [],
      "source": [
        "# Install your library here, for example the fynesse template\n",
        "# is set up to be pip installable\n",
        "%pip install git+https://github.com/jeffrey-22/ads.git\n",
        "import os, fynesse\n",
        "# 2 min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "# Import local fynesse module. Do NOT run this cell if the notebook is not run from the repo - this is a quick hack for local runs\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import os, sys, IPython\n",
        "from pathlib import Path\n",
        "try:\n",
        "    notebook_path = Path(IPython.get_ipython().run_line_magic('pwd', '')).as_posix()\n",
        "except AttributeError:\n",
        "    notebook_path = Path(__file__).resolve().as_posix()\n",
        "script_path = os.path.abspath(notebook_path)\n",
        "project_path = os.path.abspath(os.path.join(script_path, '..'))\n",
        "sys.path.append(project_path)\n",
        "import fynesse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create connections. The connections will be reused throughout the modules\n",
        "pp_database_details = fynesse.access.retreive_database_details()\n",
        "# fynesse.access.create_database(pp_database_details)\n",
        "pp_database_conn = fynesse.access.create_connection(pp_database_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7d9d674",
      "metadata": {
        "id": "d7d9d674"
      },
      "source": [
        "The schema stores price transaction data about the traded households.\n",
        "- ```transaction_unique_identifier``` and ```db_id``` are indices for transactions and for our database respectively.\n",
        "- ```price``` describes, in GBP, the price of the household.\n",
        "- ```postcode```, ```primary_addressable_object_name```, ```secondary_addressable_object_name```, ```street```, ```locality```, ```town_city```, ```district```, ```county``` describe the address. We will ultimately only use the postcode to find the latitude and longitude.\n",
        "- ```property_type``` describes one of: Detached, Semi-detached, Terraced, Flat/maisonette, Other, indicated by the initials.\n",
        "- ```new_build_flag```, ```tenure_type```, ```ppd_category_type```, ```record_status``` likely describe some categories, but they are not very helpful as we are ultimately not given these when predicting.\n",
        "\n",
        "We will do some sanity checks and general visualisation of the data in the address part."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92da8c96",
      "metadata": {
        "id": "92da8c96"
      },
      "outputs": [],
      "source": [
        "# Write the code you need for creating the table, downloading and uploading the data here. You can use as many code blocks as you need.\n",
        "# Warning: run these once when populating the database. No need to run them again just for prediction!\n",
        "# 20 min\n",
        "os.makedirs(\"tmp_data\", exist_ok=True)\n",
        "downloaded_pathnames = fynesse.access.download_price_data()\n",
        "print(f\"Downloaded files: {downloaded_pathnames}\")\n",
        "fynesse.access.create_pp_table(pp_database_conn)\n",
        "# 15m\n",
        "fynesse.access.upload_files_to_table(pp_database_conn, downloaded_pathnames, 'pp_data')\n",
        "# 11m\n",
        "fynesse.access.setup_pp_table(pp_database_conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Warning: run these once when populating the database. No need to run them again just for prediction!\n",
        "fynesse.access.create_postcode_table(pp_database_conn)\n",
        "# 10s\n",
        "postcode_filename = fynesse.access.download_postcode_data()\n",
        "# 1m\n",
        "fynesse.access.upload_files_to_table(pp_database_conn, [postcode_filename], 'postcode_data')\n",
        "# 1m\n",
        "fynesse.access.setup_postcode_table(pp_database_conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y-lttyzUtSv7",
      "metadata": {
        "id": "Y-lttyzUtSv7"
      },
      "outputs": [],
      "source": [
        "# Warning: run these once when populating the database. No need to run them again just for prediction!\n",
        "fynesse.access.create_prices_coordinates_table(pp_database_conn)\n",
        "# 20m\n",
        "joined_table_pathnames = fynesse.access.join_all_tables(downloaded_pathnames, postcode_filename, overwrite=False)\n",
        "# 10m\n",
        "fynesse.access.upload_files_to_table(pp_database_conn, joined_table_pathnames, 'prices_coordinates_data', ignore_first_row=True)\n",
        "# 9m\n",
        "fynesse.access.setup_prices_coordinates_table(pp_database_conn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df36e5d1",
      "metadata": {
        "id": "df36e5d1"
      },
      "source": [
        "## Question 2. Accessing OpenStreetMap and Assessing the Available Features\n",
        "\n",
        "In question 3 you will be given the task of constructing a prediction system for property price levels at a given location. We expect that knowledge of the local region around the property should be helpful in making those price predictions. To evaluate this we will now look at [OpenStreetMap](https://www.openstreetmap.org) as a data source.\n",
        "\n",
        "The tasks below will guide you in accessing and assessing the OpenStreetMap data. The code you write will eventually be assimilated in your python module, but documentation of what you've included and why should remain in the notebook below.\n",
        "\n",
        "Accessing OpenStreetMap through its API can be done using the python library `osmx`. Using what you have learned about the `osmx` interface in the lectures, write general code for downloading points of interest and other relevant information that you believe may be useful for predicting house prices. Remembering the perspectives we've taken on *data science as debugging*, the remarks we've made when discussing *the data crisis* of the importance of reusability in data analysis, and the techniques we've explored in the labsessions for visualising features and exploring their correlation use the notebook to document your assessment of the OpenStreetMap data as a potential source of data.\n",
        "\n",
        "The knowledge you need to do a first pass through this question will have been taught by end of lab session three (16th November 2021). You will likely want to review your answer as part of *refactoring* your code and analysis pipeline shortly before hand in.\n",
        "\n",
        "You should write reusable code that allows you to explore the characteristics of different points of interest. Looking ahead to question 3 you'll want to incorporate these points of interest in your prediction code.\n",
        "\n",
        "*5 marks*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "042a2863",
      "metadata": {
        "id": "042a2863"
      },
      "outputs": [],
      "source": [
        "# Use this cell and cells below for summarising your analysis and documenting your decision making."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model decisions\n",
        "\n",
        "There are a total of X features, they are:\n",
        "- latitude\n",
        "\n",
        "Reasonings for the features:\n",
        "- aaa\n",
        "\n",
        "The model is a GLM, with a link of $f(x) = e^x$\n",
        "\n",
        "Reasonings for the model:\n",
        "- aaa"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09a0e365",
      "metadata": {
        "id": "09a0e365"
      },
      "source": [
        "## Question 3. Addressing a Property Price Prediction Question\n",
        "\n",
        "For your final tick, we will be asking you to make house price predictions for a given location, date and property type in the UK. You will provide a function that takes input a latitude and longitude as well as the `property_type` (either type\" of property (either `F` - flat, `S` - semidetached, `D` - detached, `T` - terraced or `O` other). Create this function in the `address.py` file, for example in the form,\n",
        "\n",
        "```\n",
        "def predict_price(latitude, longitude, date, property_type):\n",
        "    \"\"\"Price prediction for UK housing.\"\"\"\n",
        "    pass\n",
        "```\n",
        "\n",
        "We suggest that you use the following approach when building your prediction.\n",
        "\n",
        "1. Select a bounding box around the housing location in latitude and longitude.\n",
        "2. Select a data range around the prediction date.\n",
        "3. Use the data ecosystem you have build above to build a training set from the relevant time period and location in the UK. Include appropriate features from OSM to improve the prediction.\n",
        "4. Train a linear model on the data set you have created.\n",
        "5. Validate the quality of the model.\n",
        "6. Provide a prediction of the price from the model, warning appropriately if your validation indicates the quality of the model is poor.\n",
        "\n",
        "Please note that the quality of predictions is not the main focus of the assignment - we expect to see models that output reasonable predictions and have positive R^2's, but you should not spend too much time on increasing the model's accuracy.\n",
        "\n",
        "The knowledge you need to do a first pass through this question will have been taught by end of lab session four (7th November 2023). You will likely want to review your answer as part of *refactoring* your code shortly before hand in.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==== Validation of current model, level 2 ====\n",
            "No warning issued\n",
            "                 Generalized Linear Model Regression Results                  \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   No. Observations:                  609\n",
            "Model:                            GLM   Df Residuals:                      594\n",
            "Model Family:                Gaussian   Df Model:                           14\n",
            "Link Function:               Identity   Scale:                      8.6974e+12\n",
            "Method:                          IRLS   Log-Likelihood:                -9928.8\n",
            "Date:                Sat, 25 Nov 2023   Deviance:                   5.1663e+15\n",
            "Time:                        00:42:33   Pearson chi2:                 5.17e+15\n",
            "No. Iterations:                     3   Pseudo R-squ. (CS):             0.1423\n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       7.487e+08   5.52e+08      1.357      0.175   -3.33e+08    1.83e+09\n",
            "x1          2599.1354   1062.104      2.447      0.014     517.449    4680.822\n",
            "x2          1.493e+08    1.1e+08      1.352      0.176   -6.71e+07    3.66e+08\n",
            "x3          1.484e+08    1.1e+08      1.345      0.179   -6.79e+07    3.65e+08\n",
            "x4          1.528e+08    1.1e+08      1.385      0.166   -6.34e+07    3.69e+08\n",
            "x5          1.492e+08    1.1e+08      1.351      0.177   -6.73e+07    3.66e+08\n",
            "x6          1.489e+08    1.1e+08      1.349      0.177   -6.74e+07    3.65e+08\n",
            "x7         -1.765e+07   1.27e+07     -1.392      0.164   -4.25e+07     7.2e+06\n",
            "x8         -9.338e+06   2.39e+07     -0.391      0.696   -5.62e+07    3.75e+07\n",
            "x9         -3.654e+09   6.17e+09     -0.593      0.553   -1.57e+10    8.43e+09\n",
            "x10        -1.922e+08   1.08e+09     -0.177      0.859   -2.32e+09    1.93e+09\n",
            "x11         8.926e+09   4.76e+09      1.873      0.061   -4.13e+08    1.83e+10\n",
            "x12          -3.6e+09   8.52e+09     -0.422      0.673   -2.03e+10    1.31e+10\n",
            "x13        -4.052e+10    2.9e+10     -1.397      0.162   -9.73e+10    1.63e+10\n",
            "x14        -1.153e+10   1.71e+10     -0.675      0.500    -4.5e+10     2.2e+10\n",
            "x15        -7.408e+09   5.42e+10     -0.137      0.891   -1.14e+11    9.89e+10\n",
            "==============================================================================\n",
            "==== End of Validation ====\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1679782.3748247623"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datetime import date\n",
        "fynesse.address.predict_price(52.206767, 0.119229, date(2023, 1, 1), 'S', pp_database_conn)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eEDpLiW0Zr_L",
      "metadata": {
        "id": "eEDpLiW0Zr_L"
      },
      "source": [
        "## Large Language Models\n",
        "\n",
        "If you used LLMs to generate or fix code in this assignment (recommended), briefly summarise the process and prompts you used. What do you think of the integration of LLMs in the data science pipeline?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "osdBm1BNaHL1",
      "metadata": {
        "id": "osdBm1BNaHL1"
      },
      "source": [
        "```GIVE YOUR WRITTEN ANSWER HERE```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DJDQPmkLldvp",
      "metadata": {
        "id": "DJDQPmkLldvp"
      },
      "source": [
        "- Some other questions are answered in [this reddit forum](https://www.reddit.com/r/CST_ADS/) or [this doc](https://docs.google.com/document/d/1GfDROyUW8HVs2eyxmJzKrYGRdVyUiVXzPcDfwOO8wX0/edit?usp=sharing). Feel free to also ask about anything that comes up."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
